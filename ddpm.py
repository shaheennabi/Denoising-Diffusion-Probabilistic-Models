import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import math

device = "cuda" if torch.cuda.is_available() else "cpu"

# -----------------------
# 1. Noise schedule
# -----------------------

T = 300

beta = torch.linspace(1e-4, 0.02, T).to(device)


alpha = 1.0 - beta

alpha_bar = torch.cumprod(alpha, dim=0)

# -----------------------
# 2. Forward process
# -----------------------

def forward_diffusion(x0, t):

    epsilon = torch.randn_like(x0)

    alpha_bar_t = alpha_bar[t].view(-1,1,1,1)

    xt = (
        torch.sqrt(alpha_bar_t) * x0 +
        torch.sqrt(1 - alpha_bar_t) * epsilon
    )

    return xt, epsilon


# -----------------------
# 3. Simple noise prediction network
# -----------------------

class SimpleCNN(nn.Module):

    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 1, 3, padding=1)

        self.time_embed = nn.Embedding(T, 32)

    def forward(self, x, t):

        t_embed = self.time_embed(t).view(-1,32,1,1)

        x = F.relu(self.conv1(x) + t_embed)
        x = F.relu(self.conv2(x))
        x = self.conv3(x)

        return x


model = SimpleCNN().to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# -----------------------
# 4. Dataset
# -----------------------

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x*2 - 1)
])

dataset = torchvision.datasets.MNIST(
    root="./data",
    train=True,
    download=True,
    transform=transform
)

loader = DataLoader(dataset, batch_size=128, shuffle=True)


# -----------------------
# 5. Training loop
# -----------------------

epochs = 3

for epoch in range(epochs):

    for x0, _ in loader:

        x0 = x0.to(device)

        t = torch.randint(0, T, (x0.shape[0],), device=device)

        xt, epsilon = forward_diffusion(x0, t)

        epsilon_pred = model(xt, t)

        loss = F.mse_loss(epsilon_pred, epsilon)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch}, Loss: {loss.item():.4f}")


# -----------------------
# 6. Sampling function
# -----------------------

@torch.no_grad()
def sample():

    x = torch.randn(1,1,28,28).to(device)

    for t in reversed(range(T)):

        t_tensor = torch.tensor([t], device=device)

        epsilon_pred = model(x, t_tensor)

        alpha_t = alpha[t]
        alpha_bar_t = alpha_bar[t]
        beta_t = beta[t]

        mean = (
            1 / torch.sqrt(alpha_t)
        ) * (
            x -
            (beta_t / torch.sqrt(1 - alpha_bar_t))
            * epsilon_pred
        )

        if t > 0:

            noise = torch.randn_like(x)

            sigma = torch.sqrt(beta_t)

            x = mean + sigma * noise

        else:

            x = mean

    return x


# -----------------------
# 7. Generate image
# -----------------------

generated = sample()

img = (generated.clamp(-1,1) + 1) / 2

plt.imshow(img.cpu().squeeze(), cmap="gray")
plt.show()




## code  generated by chat...  not  tested (only here for reference---> maybe i might someday visit this  and  explain code properly here,,with math)